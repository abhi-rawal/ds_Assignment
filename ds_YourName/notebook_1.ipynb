{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce97c3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\hp\\\\Desktop\\\\ds_assignment\\\\ds_Abhishek_Rawal\\\\csv_files\\\\historical_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 31\u001b[0m\n\u001b[0;32m     26\u001b[0m PDF_PATH        \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ROOT, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mds_report.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# üìä Load CSVs\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m trader_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRADER_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m senti_df  \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(SENTI_PATH)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# üßπ Parse Trade Time\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\hp\\\\Desktop\\\\ds_assignment\\\\ds_Abhishek_Rawal\\\\csv_files\\\\historical_data.csv'"
     ]
    }
   ],
   "source": [
    "# === DS Assignment: Trader Behavior vs Market Sentiment ===\n",
    "import os, math, json\n",
    "from datetime import datetime\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# -------------------------------\n",
    "# üóÇÔ∏è Folder Setup\n",
    "# -------------------------------\n",
    "ROOT = \"ds_Abhishek_Rawal\"  # your folder name\n",
    "CSV_DIR = os.path.join(ROOT, \"csv_files\")\n",
    "OUT_DIR = os.path.join(ROOT, \"outputs\")\n",
    "\n",
    "os.makedirs(CSV_DIR, exist_ok=True)\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------------------\n",
    "# üìÅ Paths (update if needed)\n",
    "# -------------------------------\n",
    "# Use raw strings (r\"\") to avoid escape errors on Windows\n",
    "TRADER_PATH = r\"C:\\Users\\hp\\Desktop\\ds_assignment\\ds_YourName\\csv_files\\historical_data.csv\"\n",
    "SENTI_PATH  = r\"C:\\Users\\hp\\Desktop\\ds_assignment\\ds_YourName\\csv_files\\fear_greed_index.csv\"\n",
    "\n",
    "MERGED_CSV_PATH = os.path.join(CSV_DIR, \"merged_sentiment_trades.csv\")\n",
    "PDF_PATH        = os.path.join(ROOT, \"ds_report.pdf\")\n",
    "\n",
    "# -------------------------------\n",
    "# üìä Load CSVs\n",
    "# -------------------------------\n",
    "trader_df = pd.read_csv(TRADER_PATH)\n",
    "senti_df  = pd.read_csv(SENTI_PATH)\n",
    "\n",
    "# -------------------------------\n",
    "# üßπ Parse Trade Time\n",
    "# -------------------------------\n",
    "if \"Timestamp IST\" in trader_df.columns:\n",
    "    trader_df[\"trade_dt\"] = pd.to_datetime(trader_df[\"Timestamp IST\"], dayfirst=True, errors=\"coerce\")\n",
    "elif \"Timestamp\" in trader_df.columns:\n",
    "    def parse_epoch_ms(x):\n",
    "        try:\n",
    "            val = int(float(x))\n",
    "            if len(str(val)) <= 10:  # seconds ‚Üí ms\n",
    "                val = val * 1000\n",
    "            return pd.to_datetime(val, unit=\"ms\")\n",
    "        except Exception:\n",
    "            return pd.NaT\n",
    "    trader_df[\"trade_dt\"] = trader_df[\"Timestamp\"].apply(parse_epoch_ms)\n",
    "elif \"time\" in trader_df.columns:\n",
    "    trader_df[\"trade_dt\"] = pd.to_datetime(trader_df[\"time\"], errors=\"coerce\")\n",
    "else:\n",
    "    trader_df[\"trade_dt\"] = pd.NaT\n",
    "\n",
    "trader_df[\"trade_date\"] = trader_df[\"trade_dt\"].dt.date\n",
    "\n",
    "# -------------------------------\n",
    "# üî¢ Convert Numeric Columns Safely\n",
    "# -------------------------------\n",
    "for col in [\"Execution Price\", \"Size Tokens\", \"Size USD\", \"Closed PnL\", \"Fee\"]:\n",
    "    if col in trader_df.columns:\n",
    "        trader_df[col] = pd.to_numeric(trader_df[col], errors=\"coerce\")\n",
    "\n",
    "# -------------------------------\n",
    "# üîÅ Side Normalization (fixed .upper() bug)\n",
    "# -------------------------------\n",
    "if \"Side\" in trader_df.columns:\n",
    "    trader_df[\"side_norm\"] = trader_df[\"Side\"].astype(str).str.upper().str.strip()\n",
    "elif \"Direction\" in trader_df.columns:\n",
    "    trader_df[\"side_norm\"] = trader_df[\"Direction\"].astype(str).str.upper().str.strip()\n",
    "else:\n",
    "    trader_df[\"side_norm\"] = np.nan\n",
    "\n",
    "# üßÆ Profit Label\n",
    "trader_df[\"is_profit\"] = np.where(trader_df.get(\"Closed PnL\", pd.Series([np.nan]*len(trader_df))).fillna(0) > 0, 1, 0)\n",
    "\n",
    "# -------------------------------\n",
    "# üìà Parse Sentiment Data\n",
    "# -------------------------------\n",
    "if \"date\" in senti_df.columns:\n",
    "    senti_df[\"senti_date\"] = pd.to_datetime(senti_df[\"date\"], errors=\"coerce\").dt.date\n",
    "elif \"Date\" in senti_df.columns:\n",
    "    senti_df[\"senti_date\"] = pd.to_datetime(senti_df[\"Date\"], errors=\"coerce\").dt.date\n",
    "else:\n",
    "    if \"timestamp\" in senti_df.columns:\n",
    "        senti_df[\"senti_date\"] = pd.to_datetime(senti_df[\"timestamp\"], unit=\"s\", errors=\"coerce\").dt.date\n",
    "    else:\n",
    "        senti_df[\"senti_date\"] = pd.NaT\n",
    "\n",
    "def map_sentiment(cls):\n",
    "    if not isinstance(cls, str):\n",
    "        return np.nan\n",
    "    c = cls.strip().lower()\n",
    "    if \"extreme fear\" in c or c == \"fear\":\n",
    "        return \"Fear\"\n",
    "    if \"extreme greed\" in c or c == \"greed\":\n",
    "        return \"Greed\"\n",
    "    if \"neutral\" in c:\n",
    "        return \"Neutral\"\n",
    "    if \"fear\" in c:\n",
    "        return \"Fear\"\n",
    "    if \"greed\" in c:\n",
    "        return \"Greed\"\n",
    "    return \"Neutral\"\n",
    "\n",
    "if \"classification\" in senti_df.columns:\n",
    "    senti_df[\"sentiment_bucket\"] = senti_df[\"classification\"].apply(map_sentiment)\n",
    "elif \"Classification\" in senti_df.columns:\n",
    "    senti_df[\"sentiment_bucket\"] = senti_df[\"Classification\"].apply(map_sentiment)\n",
    "else:\n",
    "    senti_df[\"sentiment_bucket\"] = np.nan\n",
    "\n",
    "score_col = \"value\" if \"value\" in senti_df.columns else None\n",
    "if score_col:\n",
    "    senti_df[\"sentiment_score\"] = pd.to_numeric(senti_df[score_col], errors=\"coerce\")\n",
    "else:\n",
    "    senti_df[\"sentiment_score\"] = np.nan\n",
    "\n",
    "senti_keep = senti_df[[\"senti_date\", \"sentiment_bucket\", \"sentiment_score\"]].dropna(subset=[\"senti_date\"])\n",
    "\n",
    "# -------------------------------\n",
    "# üîó Merge Trader & Sentiment\n",
    "# -------------------------------\n",
    "merged = pd.merge(trader_df, senti_keep, left_on=\"trade_date\", right_on=\"senti_date\", how=\"left\")\n",
    "merged[\"sentiment_bucket\"] = merged[\"sentiment_bucket\"].fillna(\"Unknown\")\n",
    "merged.to_csv(MERGED_CSV_PATH, index=False)\n",
    "\n",
    "# -------------------------------\n",
    "# üìä Aggregations & Summaries\n",
    "# -------------------------------\n",
    "summary_by_senti = merged.groupby(\"sentiment_bucket\").agg({\n",
    "    \"Closed PnL\": [\"count\", \"mean\", \"median\", \"std\", \"sum\"],\n",
    "    \"Size USD\": [\"mean\", \"median\", \"std\", \"sum\"],\n",
    "    \"sentiment_score\": [\"mean\"]\n",
    "}).reset_index()\n",
    "\n",
    "winrate = merged.groupby(\"sentiment_bucket\")[\"is_profit\"].mean().reset_index().rename(columns={\"is_profit\": \"win_rate\"})\n",
    "\n",
    "# -------------------------------\n",
    "# üìâ Visualizations\n",
    "# -------------------------------\n",
    "# 1Ô∏è‚É£ Average PnL by Sentiment\n",
    "if \"Closed PnL\" in merged.columns:\n",
    "    avg_pnl = merged.groupby(\"sentiment_bucket\")[\"Closed PnL\"].mean().reindex([\"Fear\",\"Neutral\",\"Greed\",\"Unknown\"]).dropna()\n",
    "    plt.figure()\n",
    "    avg_pnl.plot(kind=\"bar\")\n",
    "    plt.title(\"Average Closed PnL by Sentiment\")\n",
    "    plt.xlabel(\"Sentiment\")\n",
    "    plt.ylabel(\"Average Closed PnL\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, \"avg_pnl_by_sentiment.png\"), dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "# 2Ô∏è‚É£ Boxplot ‚Äì Trade Size USD\n",
    "if \"Size USD\" in merged.columns:\n",
    "    plt.figure()\n",
    "    order = [c for c in [\"Fear\", \"Neutral\", \"Greed\", \"Unknown\"] if c in merged[\"sentiment_bucket\"].unique().tolist()]\n",
    "    data = [merged.loc[merged[\"sentiment_bucket\"]==c, \"Size USD\"].dropna().values for c in order]\n",
    "    plt.boxplot(data, labels=order, showmeans=True)\n",
    "    plt.title(\"Trade USD Size Distribution by Sentiment\")\n",
    "    plt.xlabel(\"Sentiment\")\n",
    "    plt.ylabel(\"Trade Size (USD)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, \"size_usd_by_sentiment.png\"), dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "# 3Ô∏è‚É£ Side Distribution (BUY/SELL)\n",
    "if \"side_norm\" in merged.columns and merged[\"side_norm\"].notna().any():\n",
    "    counts = merged.groupby([\"sentiment_bucket\", \"side_norm\"]).size().unstack(fill_value=0)\n",
    "    counts = counts.reindex(index=[c for c in [\"Fear\",\"Neutral\",\"Greed\",\"Unknown\"] if c in counts.index])\n",
    "    x = np.arange(len(counts))\n",
    "    plt.figure()\n",
    "    bottom = np.zeros(len(counts))\n",
    "    for side in counts.columns:\n",
    "        plt.bar(x, counts[side].values, bottom=bottom, label=str(side))\n",
    "        bottom = bottom + counts[side].values\n",
    "    plt.xticks(x, counts.index.tolist())\n",
    "    plt.title(\"Trade Side Counts by Sentiment\")\n",
    "    plt.xlabel(\"Sentiment\")\n",
    "    plt.ylabel(\"Trade Count\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, \"trade_side_distribution.png\"), dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "# 4Ô∏è‚É£ Correlation Heatmap\n",
    "num_cols = merged.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if len(num_cols) >= 2:\n",
    "    corr = merged[num_cols].corr()\n",
    "    plt.figure()\n",
    "    plt.imshow(corr, aspect=\"auto\")\n",
    "    plt.xticks(range(len(num_cols)), num_cols, rotation=90)\n",
    "    plt.yticks(range(len(num_cols)), num_cols)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Correlation Heatmap (Numeric Columns)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, \"correlation_heatmap.png\"), dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# üìÑ PDF Report Generation\n",
    "# -------------------------------\n",
    "with PdfPages(PDF_PATH) as pdf:\n",
    "    plt.figure(figsize=(8.5, 11))\n",
    "    plt.axis(\"off\")\n",
    "    lines = [\n",
    "        \"Data Science Report: Trader Behavior vs Market Sentiment\",\n",
    "        f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "        \"\",\n",
    "        f\"Total Trades: {len(merged):,}\",\n",
    "    ]\n",
    "    if \"Closed PnL\" in merged.columns:\n",
    "        wr = (merged[\"Closed PnL\"] > 0).mean()\n",
    "        lines.append(f\"Overall Win Rate: {wr*100:.2f}%\")\n",
    "    y = 0.95\n",
    "    for line in lines:\n",
    "        plt.text(0.05, y, line, fontsize=12, va=\"top\")\n",
    "        y -= 0.04\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    for name in [\"avg_pnl_by_sentiment.png\", \"size_usd_by_sentiment.png\",\n",
    "                 \"trade_side_distribution.png\", \"correlation_heatmap.png\"]:\n",
    "        pth = os.path.join(OUT_DIR, name)\n",
    "        if os.path.exists(pth):\n",
    "            img = plt.imread(pth)\n",
    "            plt.figure(figsize=(11, 8.5))\n",
    "            plt.imshow(img)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(name)\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "\n",
    "# -------------------------------\n",
    "# ‚úÖ Show Results in Console\n",
    "# -------------------------------\n",
    "print(\"\\n===== Summary by Sentiment =====\")\n",
    "print(summary_by_senti)\n",
    "print(\"\\n===== Win Rate by Sentiment =====\")\n",
    "print(winrate)\n",
    "print(\"\\nAll outputs and ds_report.pdf generated successfully ‚úÖ\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
